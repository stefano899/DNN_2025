{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VERIFICA PRESENZA DI CUDA\n",
    "Con nvidia-smi nel prompt si vede anche la versione di Cuda"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1416a182ed7008e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c5a904dedfbd056",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DOWNLOADING DATASET"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ec29b000effee7c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data= datasets.FashionMNIST(root='data', train=True, download=True, transform=ToTensor(),)\n",
    "\n",
    "test_data = datasets.FashionMNIST(root='data', train=False, download=True, transform=ToTensor(),)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "270b3c042025f252",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATA LOADER"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "943285fe8adc2eb5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "def handle_dataset():\n",
    "    train_data = datasets.FashionMNIST(root='data', train=True, download=True, transform=ToTensor(), )\n",
    "    test_data = datasets.FashionMNIST(root='data', train=False, download=True, transform=ToTensor(), )\n",
    "\n",
    "    labels_map = { # Classes need to be predicted\n",
    "        0: 'T-shirt',\n",
    "        1: 'Trouser',\n",
    "        2: 'Pullover',\n",
    "        3: 'Dress',\n",
    "        4: 'Coat',\n",
    "        5: 'Sandal',\n",
    "        6: 'Shirt',\n",
    "        7: 'Sneaker',\n",
    "        8: 'Bag',\n",
    "        9: 'Ankle Boot',\n",
    "    }\n",
    "    batch_size = 128  # For processing simultaneously 128 images at every weigth update\n",
    "\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size,\n",
    "                                  shuffle=True)  # For every iteration, dataset is divided into gropus of 128 samples. Shuffle helps generalizing the model\n",
    "\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size)  # Same as train_dataloader but for the test\n",
    "\n",
    "    return train_dataloader, test_dataloader, labels_map\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc932b3fd1b04c00",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DEFYINING THE INITIALIZATION KERNEL AND WEIGHTS\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f539427361a4ac9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bulding the Neural Net\n",
    "Here is were the different net classes (CNNs) are declared. We'll divide the architectures into 2 sets: A1 and A2.\n",
    "CNNs of A1 share the same architectures, but they differ in the initialization/training of the kernels, and the same happens for A2. \n",
    "We have 3 types of the initialization schemas:\n",
    "-  HF;\n",
    "- HT;\n",
    "- DT\n",
    "\n",
    "NB: WHEN YOU HAVE DECIDED TO USE THE DESIRED ARCHITECTURE, CHANGE THE NAME OF THE CLASS WITH \"Net\"\n",
    "\n",
    "## About the kernel initialization\n",
    "\n",
    "The dataset contains grayscale images, wich have 1 channel and a dimension of 28x28 pixels.\n",
    "The initial kernel will be of size 3, padding 1 and stride 1 and with 5 output channels (5 kernels)\n",
    "\n",
    "For understanding how will be the size of the image after applying a convolution layer, we have to see this formula:\n",
    "$$O = \\frac{(I - K + 2P)}{S} + 1$$\n",
    "\n",
    "Where *I* is the size of the input, *K* is the size of the kernel, *P* is the padding and *S* is the stride\n",
    "This formula returns the shape of the image after 1 convolution layer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bf6822b69b67a92"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SET A1\n",
    "### HF"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c3ab679a25b88d3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "#\n",
    "class A1HF(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(A1HF, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)  # Convolution layer\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(5 * 14 * 14, 100)  # first number is to decoding the 3d tensor vector into a 1D dimensional vector, 100 is the number of output neurons of fc1. I chosed 100 because is a good tradeoff between speed and leaning capacity\n",
    "        self.fc2 = nn.Linear(100, len(classes))  # Final fully connected layer. This is the layer that makes the preictions.\n",
    "        self.relu = nn.ReLU()  # Activation Function\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu(self.conv1(x)))\n",
    "\n",
    "        x = self.flatten(x)  # x becomes a 2D vector\n",
    "\n",
    "        x = self.relu(self.fc1(x))  # actv. function applied on the first fully connected layer of output\n",
    "\n",
    "        x = self.fc2(x)  # Prediction\n",
    "        return x\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f4cb37229cf3338",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### HT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91362a8380f33776"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "#A1_HT\n",
    "class A1HT(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(A1HT, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)  # Convolution layer\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(5 * 14 * 14, 100)  # first number is to decoding the 3d tensor vector into a 1D dimensional vector, 100 is the number of output neurons of fc1. I chosed 100 because is a good tradeoff between speed and leaning capacity\n",
    "        self.fc2 = nn.Linear(100, len(classes))  # Final fully connected layer. This is the layer that makes the preictions.\n",
    "        self.relu = nn.ReLU()  # Activation Function\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def set_initial_kernels(self):\n",
    "        # Definito by hand i primi 5 kernels\n",
    "        kernel1 = torch.tensor([[0, 1, 0],\n",
    "                                [1, 1, 1],\n",
    "                                [0, 1, 0]], dtype=torch.float32)\n",
    "\n",
    "        kernel2 = torch.tensor([[1, 0, 1],\n",
    "                                [0, 1, 0],\n",
    "                                [1, 0, 1]], dtype=torch.float32)\n",
    "\n",
    "        kernel3 = torch.tensor([[1, 1, 1],\n",
    "                                [0, 0, 0],\n",
    "                                [1, 1, 1]], dtype=torch.float32)\n",
    "\n",
    "        kernel4 = torch.tensor([[0, 1, 0],\n",
    "                                [0, 0, 0],\n",
    "                                [1, 0, 1]], dtype=torch.float32)\n",
    "\n",
    "        kernel5 = torch.tensor([[1, 1, 0],\n",
    "                                [1, 0, 0],\n",
    "                                [0, 0, 0]], dtype=torch.float32)\n",
    "        kernels = [kernel1, kernel2, kernel3, kernel4, kernel5]  # list of\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # I pesi di conv1 hanno shape [5, 1, 3, 3] (5 kernels, 1 canale, dimensione 3x3)\n",
    "            # Assegno ciascun pattern al corrispondente kernel per l'unico canale in ingresso.\n",
    "            for k, kernel in enumerate(kernels):\n",
    "                self.conv1.weight[k, 0] = kernel\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu(self.conv1(x)))\n",
    "\n",
    "        x = self.flatten(x)  # x becomes a 2D vector\n",
    "\n",
    "        x = self.relu(self.fc1(x))  # actv. function applied on the first fully connected layer of output\n",
    "\n",
    "        x = self.fc2(x)  # Prediction\n",
    "        return x\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a009ebb15cc77b5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "325dfea149184acc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "#A1_DT\n",
    "class A1DT(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(A1DT, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)  # Convolution layer\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(5 * 14 * 14, 100)  # first number is to decoding the 3d tensor vector into a 1D dimensional vector, 100 is the number of output neurons of fc1. I chosed 100 because is a good tradeoff between speed and leaning capacity\n",
    "        self.fc2 = nn.Linear(100, len(classes))  # Final fully connected layer. This is the layer that makes the preictions.\n",
    "        self.relu = nn.ReLU()  # Activation Function\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu(self.conv1(x)))\n",
    "\n",
    "        x = self.flatten(x)  # x becomes a 2D vector\n",
    "\n",
    "        x = self.relu(self.fc1(x))  # actv. function applied on the first fully connected layer of output\n",
    "\n",
    "        x = self.fc2(x)  # Prediction\n",
    "        return x\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72e31f59f8435926",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set A2\n",
    "### HF"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f5304b84a525f5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "#A2_HF\n",
    "class A2HF(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(A2HF, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)  # Convolution layer\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(5 * 14 * 14, 100)  # first number is to decoding the 3d tensor vector into a 1D dimensional vector, 100 is the number of output neurons of fc1. I chosed 100 because is a good tradeoff between speed and leaning capacity\n",
    "        self.fc2 = nn.Linear(100, len(classes))  # Final fully connected layer. This is the layer that makes the preictions.\n",
    "        self.relu = nn.ReLU()  # Activation Function\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def set_initial_kernels(self):\n",
    "        # Definito by hand i primi 5 kernels\n",
    "        kernel1 = torch.tensor([[0, 1, 0],\n",
    "                                [1, 1, 1],\n",
    "                                [0, 1, 0]], dtype=torch.float32)\n",
    "\n",
    "        kernel2 = torch.tensor([[1, 0, 1],\n",
    "                                [0, 1, 0],\n",
    "                                [1, 0, 1]], dtype=torch.float32)\n",
    "\n",
    "        kernel3 = torch.tensor([[1, 1, 1],\n",
    "                                [0, 0, 0],\n",
    "                                [1, 1, 1]], dtype=torch.float32)\n",
    "\n",
    "        kernel4 = torch.tensor([[0, 1, 0],\n",
    "                                [0, 0, 0],\n",
    "                                [1, 0, 1]], dtype=torch.float32)\n",
    "\n",
    "        kernel5 = torch.tensor([[1, 1, 0],\n",
    "                                [1, 0, 0],\n",
    "                                [0, 0, 0]], dtype=torch.float32)\n",
    "        kernels = [kernel1, kernel2, kernel3, kernel4, kernel5]  # list of\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # I pesi di conv1 hanno shape [5, 1, 3, 3] (5 kernels, 1 canale, dimensione 3x3)\n",
    "            # Assegno ciascun pattern al corrispondente kernel per l'unico canale in ingresso.\n",
    "            for k, kernel in enumerate(kernels):\n",
    "                self.conv1.weight[k, 0] = kernel\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu(self.conv1(x)))\n",
    "\n",
    "        x = self.flatten(x)  # x becomes a 2D vector\n",
    "\n",
    "        x = self.relu(self.fc1(x))  # actv. function applied on the first fully connected layer of output\n",
    "\n",
    "        x = self.fc2(x)  # Prediction\n",
    "        return x\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7af36f698d71c15",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### HT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "706682af836b399c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "# A2_HT\n",
    "class A2HT(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(A2HT, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)  # Convolution layer\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(5 * 14 * 14, 100)  # first number is to decoding the 3d tensor vector into a 1D dimensional vector, 100 is the number of output neurons of fc1. I chosed 100 because is a good tradeoff between speed and leaning capacity\n",
    "        self.fc2 = nn.Linear(100, len(classes))  # Final fully connected layer. This is the layer that makes the preictions.\n",
    "        self.relu = nn.ReLU()  # Activation Function\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def set_initial_kernels(self):\n",
    "        # Definito by hand i primi 5 kernels\n",
    "        kernel1 = torch.tensor([[0, 1, 0],\n",
    "                                [1, 1, 1],\n",
    "                                [0, 1, 0]], dtype=torch.float32)\n",
    "\n",
    "        kernel2 = torch.tensor([[1, 0, 1],\n",
    "                                [0, 1, 0],\n",
    "                                [1, 0, 1]], dtype=torch.float32)\n",
    "\n",
    "        kernel3 = torch.tensor([[1, 1, 1],\n",
    "                                [0, 0, 0],\n",
    "                                [1, 1, 1]], dtype=torch.float32)\n",
    "\n",
    "        kernel4 = torch.tensor([[0, 1, 0],\n",
    "                                [0, 0, 0],\n",
    "                                [1, 0, 1]], dtype=torch.float32)\n",
    "\n",
    "        kernel5 = torch.tensor([[1, 1, 0],\n",
    "                                [1, 0, 0],\n",
    "                                [0, 0, 0]], dtype=torch.float32)\n",
    "\n",
    "        kernels = [kernel1, kernel2, kernel3, kernel4, kernel5]  # list of\n",
    "\n",
    "        for k, kernel in enumerate(kernels):\n",
    "            self.conv1.weight[k, 0] = kernel\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu(self.conv1(x)))\n",
    "\n",
    "        x = self.flatten(x)  # x becomes a 2D vector\n",
    "\n",
    "        x = self.relu(self.fc1(x))  # actv. function applied on the first fully connected layer of output\n",
    "\n",
    "        x = self.fc2(x)  # Prediction\n",
    "        return x\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f99dc1579004a940",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77fb5cbb82f8c22f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "#A2_DT\n",
    "class A2DT(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(A2DT, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)  # Convolution layer\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(5 * 14 * 14, 100)  # first number is to decoding the 3d tensor vector into a 1D dimensional vector, 100 is the number of output neurons of fc1. I chosed 100 because is a good tradeoff between speed and leaning capacity\n",
    "        self.fc2 = nn.Linear(100, len(classes))  # Final fully connected layer. This is the layer that makes the preictions.\n",
    "        self.relu = nn.ReLU()  # Activation Function\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu(self.conv1(x)))\n",
    "\n",
    "        x = self.flatten(x)  # x becomes a 2D vector\n",
    "\n",
    "        x = self.relu(self.fc1(x))  # actv. function applied on the first fully connected layer of output\n",
    "\n",
    "        x = self.fc2(x)  # Prediction\n",
    "        return x\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "811e2afef144425b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TRAIN_LOOP"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aed4db41fb8f1c5a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, epoch, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    print(f\"Training set of size: {size}\")\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):  # (X = input, y = target)\n",
    "        X, y = X.to(device), y.to(device)  # Setting of 2 architectures\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()  # Loss function calculating the zero-gradient descent\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 1000 == 0:  # every 1000 batch it prints the loss\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            current_loss = current / size\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    # torch save model with torch.save()\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,  # l'epoca corrente\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }\n",
    "\n",
    "    # Definisci il percorso della cartella dei checkpoint\n",
    "    checkpoint_dir = r'C:\\Users\\stefa\\Desktop\\DNN2025\\DNNStefano\\DNN\\CheckpointsNotebook'\n",
    "\n",
    "    # Se la cartella non esiste, la creiamo\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    # Costruiamo il percorso completo del file checkpoint\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'epoch_{epoch}_Model_CNN_A1_DT.pt')\n",
    "\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "308601ce43acb109",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TEST_LOOP"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d971be3192c5050"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return 100 * correct, test_loss\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf5f7c710d718dd4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# START"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8b75058fa3f6a1a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def start(epochs, iteratore, device, train_loader, test_loader):\n",
    "    for iterator in range(iteratore, epochs):\n",
    "        print(f\"Epoch {iterator + 1}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer, iterator + 1, device)\n",
    "        accuracy, loss = test_loop(test_dataloader, model, loss_fn, device)\n",
    "        accuracies.append(accuracy)\n",
    "        losses.append(loss)\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"START\")\n",
    "    train_dataloader, test_dataloader, labels_map = handle_dataset()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = A1HT(labels_map)  # Dichiarazione di un oggetto di tipo Net\n",
    "    model.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    model.set_initial_kernels() # check if the class has this method. Otherwise, comment it\n",
    "    learning_rate = 1e-4\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    epochs = 20\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    iterator = 0\n",
    "    start(epochs, iterator, device, train_dataloader, test_dataloader)\n",
    "\n",
    "    epochs = range(1, len(accuracies) + 1)\n",
    "\n",
    "    # comment if it creates problems\n",
    "    matplotlib.use('TkAgg')  # Oppure 'Qt5Agg' se hai PyQt5 installato\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)  # Primo subplot\n",
    "    plt.plot(epochs, accuracies, marker='o', label=\"Accuracy\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Accuracy Over Epochs')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)  # Secondo subplot\n",
    "    plt.plot(epochs, losses, marker='o', label=\"Loss\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Loss Over Epochs')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4eb03d2edcf00ba",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Per ottenere informazioni di un checkpoint"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfc5f32adbbddaa5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "checkpoint_path = r'C:\\Users\\stefa\\Desktop\\DNN_2025\\Architetture\\Checkpoints\\SetA1\\A1DT\\epoch_5_Model_CNN_A1DT.pth'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "checkpoint"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75cb444a4d835fd2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint A1DT Keys: dict_keys(['model_state_dict'])\n",
      "Checkpoint A2HT Keys: dict_keys(['model_state_dict'])\n",
      "weights_A1HT.shape: tensor([[[[-0.0154,  0.2141,  0.3755],\n",
      "          [-0.1181,  0.1458,  0.4804],\n",
      "          [-0.0644,  0.4549,  0.0154]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1725,  0.3713, -0.0484],\n",
      "          [ 0.0533,  0.0843, -0.3922],\n",
      "          [ 0.0318,  0.3630,  0.0139]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3294,  0.0549,  0.0895],\n",
      "          [ 0.2067,  0.1893,  0.3953],\n",
      "          [ 0.3433,  0.1022, -0.2267]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2402,  0.1688, -0.3027],\n",
      "          [-0.3424, -0.4309, -0.2804],\n",
      "          [-0.3145, -0.0862, -0.0420]]],\n",
      "\n",
      "\n",
      "        [[[-0.3060,  0.3026, -0.3550],\n",
      "          [ 0.2466, -0.4196, -0.1897],\n",
      "          [ 0.4299, -0.2667,  0.3686]]]], device='cuda:0')\n",
      "weights_A2HT.shape: tensor([[[[-0.3907, -0.3157, -0.2261],\n",
      "          [-0.4974, -0.1876, -0.2189],\n",
      "          [-0.2164, -0.2368,  0.5098]]],\n",
      "\n",
      "\n",
      "        [[[-0.4348, -0.4456,  0.4629],\n",
      "          [ 0.1217,  0.0720, -0.0369],\n",
      "          [ 0.4530,  0.3005, -0.2995]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0304, -0.0752,  0.3151],\n",
      "          [ 0.2554,  0.3839,  0.1172],\n",
      "          [ 0.2807,  0.1071,  0.1876]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3465, -0.0732, -0.1766],\n",
      "          [ 0.1340, -0.3337,  0.0515],\n",
      "          [ 0.3218, -0.1160, -0.1123]]],\n",
      "\n",
      "\n",
      "        [[[-0.0781, -0.0525,  0.0758],\n",
      "          [ 0.3089,  0.4583,  0.3633],\n",
      "          [-0.0796, -0.3346, -0.1740]]]], device='cuda:0')\n",
      "Attenzione! I pesi iniziali sono diversi.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Carica i checkpoint\n",
    "checkpoint1 = torch.load(\"Checkpoints/SetA1/A1DT/epoch_1_Model_CNN_A1DT.pth\")\n",
    "checkpoint2 = torch.load(\"PrevTraining/Checkpoints/SetA1/A1DT/epoch_1_Model_CNN_A1DT.pth\")\n",
    "\n",
    "# Controlla le chiavi disponibili\n",
    "print(\"Checkpoint A1DT Keys:\", checkpoint1.keys())\n",
    "print(\"Checkpoint A2HT Keys:\", checkpoint2.keys())\n",
    "\n",
    "# Confronta i pesi del primo layer\n",
    "layer_name = \"conv1.weight\"  # Modifica con il nome corretto del primo layer nel tuo modello\n",
    "weights_A1DT = checkpoint1[\"model_state_dict\"][layer_name]\n",
    "weights_A2HT = checkpoint2[\"model_state_dict\"][layer_name]\n",
    "print(f\"weights_A1HT.shape: {weights_A1DT}\")\n",
    "print(f\"weights_A2HT.shape: {weights_A2HT}\")\n",
    "\n",
    "# Verifica la coerenza\n",
    "if torch.allclose(weights_A1DT, weights_A2HT, atol=1e-6):\n",
    "    print(\"I pesi iniziali del primo layer sono coerenti tra le reti!\")\n",
    "else:\n",
    "    print(\"Attenzione! I pesi iniziali sono diversi.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T12:03:35.913029Z",
     "start_time": "2025-05-22T12:03:35.792984Z"
    }
   },
   "id": "9827150de3dd838d",
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
